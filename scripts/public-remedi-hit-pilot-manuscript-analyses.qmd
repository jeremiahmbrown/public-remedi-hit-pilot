---
title: "REMEDI HIT Pilot Manuscript Analyses"
author: "Jeremiah Brown"
format: html
code-fold: true
editor: visual
execute: 
  warning: false
---

Load packages and custom functions

```{r}
#| label: load-packages
#| echo: false
library(tidyverse)
library(qualtRics)
library(lubridate)
library(gtsummary)
library(discAUC)
library(labelVector)
library(report)
library(ggsci)
library(ggpubr)
library(gt)
library(effectsize)
library(performance)

#I copied this function mostly from sean gilroy's discountingtool's package. # https://github.com/miyamot0/discountingtools

jb_rules <- function(dat, idCol = "id", ll = 1000) {
  
  if (!idCol %in% colnames(dat)) {
    stop("Id column not found, please check naming")
  } else {
    colnames(dat)[colnames(dat) == idCol] <- 'id'
  }
  
  lengthReturn <- length(unique(dat$id))
  
  returnFrame <- data.frame(id = rep(NA, lengthReturn),
                            C1 = rep(NA, lengthReturn),
                            C2 = rep(NA, lengthReturn))
  
  mIndex <- 1
  
  for (i in unique(dat$id)) {
    # print(i) # added this line to show what id might violate assumptions of function
    subsetData <- dat[dat$id == i,]
    
    criteriaOne <- TRUE
    criteriaTwo <- TRUE
    
    subsetData <- subsetData[order(subsetData$delay), ]
    
    for (j in 2:length(subsetData$delay)) {
      prev = subsetData[j-1, ]$ip
      curr = subsetData[j, ]$ip
      
      if ((curr - prev) > (.2 * ll)) {
        criteriaOne = FALSE
      }
    }
    
    prev <- subsetData[1, ]$ip
    curr <- subsetData[length(subsetData$delay), ]$ip
    
    if ((prev - curr) < (.1 * ll)) {
      criteriaTwo = FALSE
    }
    
    returnFrame[mIndex, ]$id <- i
    returnFrame[mIndex, ]$C1 <- criteriaOne
    returnFrame[mIndex, ]$C2 <- criteriaTwo
    
    mIndex <- mIndex + 1
    
  }
  
  returnFrame
}


```

Load, shape, clean data from qualtrics or CSV

```{r}
#| label: load-data
#| output: FALSE

rawdata <- read_csv("data/deidentified-rawdata.csv")

#add a column to calculate the number of indicated medical diagnoses on each diagnosis question
#we add it to the rawdata df because we need these numbers for all responses in order to 
#create the flow diagram.

rawdata <- rawdata %>% 
  select(ResponseId, diagnoses1_10:diagnoses1_12) %>%  
  mutate(diagnoses1_total = rowSums(!is.na(.)) - 1) |> 
  select(ResponseId, diagnoses1_total) |> 
  left_join(rawdata, by = "ResponseId") 

rawdata <- rawdata %>% 
  select(ResponseId, diagnoses2_10:diagnoses2_12) %>%  
  mutate(diagnoses2_total = rowSums(!is.na(.)) - 1) |> 
  select(ResponseId, diagnoses2_total) |> 
  left_join(rawdata, by = "ResponseId")

#pull only the finishers for our study
data <- rawdata %>% 
  filter(mTurkCode != 'NA' & Status == "IP Address" & group != 'NA' &
           StartDate > '2022-02-10 11:10:00') %>%
  mutate(mTurkCode = as.factor(mTurkCode), id = row_number(),
         id = as.factor(id), group = as.factor(group)) %>% 
  select(ResponseId, id, Progress, mTurkCode, diagnoses1_score,
         diagnoses2_score, BMI, age = Q3988, edu = Q3982, gender = Q3987,
         income = Q3984, cont_ladder, hba1c = Q206,
        `1_eft_ac`, `2_eft_ac`, `3_eft_ac`, `4_eft_ac`, `5_eft_ac`,
         `6_eft_ac`, `7_eft_ac`, group:ncc_ac) %>% 
  mutate(age = as.numeric(age)) |> 
  mutate(eft_ac_1 
         = case_when(
    `1_eft_ac` == "$1000 now" ~ .25,
    `1_eft_ac` == "$500 now" ~ 0),
    eft_ac_3 = case_when(
    `3_eft_ac` == "$1000 now" ~ .25,
    `3_eft_ac` == "$500 now" ~ 0),
    eft_ac_5 = case_when(
    `5_eft_ac` == "$1000 now" ~ .25,
    `5_eft_ac` == "$500 now" ~ 0),
    eft_ac_7 = case_when(
    `7_eft_ac` == "$1000 now" ~ .25,
    `7_eft_ac` == "$500 now" ~ 0),
    eft_ac_correct = eft_ac_1 + eft_ac_3 + eft_ac_5 + eft_ac_7)

#recode income as an ordered factor

data$income <- factor(data$income, levels = c("$0 to $9,999",
                                              "$10,000 to $19,999",
                                              "$20,000 to $29,999",
                                              "$30,000 to $39,999",
                                              "$40,000 to $49,999",
                                              "$50,000 to $59,999",
                                              "$60,000 to $69,999",
                                              "$70,000 to $79,999",
                                              "$80,000 to $89,999",
                                              "$90,000 to $99,999",
                                              "$100,000 to $109,999",
                                              "$130,000 to $139,999",
                                              "$170,000 to $179,999",
                                              "$180,000 to $189,999"))

#recode income as a continuous variable in include in table 1
data$income <- data |> 
  mutate(income = as.numeric(income),
         income = case_when(
           income == 1 ~ 4999.5,
           income == 2 ~ 1499.5,
           income == 3 ~ 24999.5,
           income == 4 ~ 34999.5, 
           income == 5 ~ 49999.5, 
           income == 6 ~ 54999.5,
           income == 7 ~ 64999.5,
           income == 8 ~ 74999.5,
           income == 9 ~ 84999.5,
           income == 10 ~ 94999.5,
           income == 11 ~ 104999.5,
           income == 12 ~ 134999.5,
           income == 13 ~ 174999.5, 
           income == 14 ~ 184999.5
         )) |> 
  pull(income)

data$group <- recode_factor(data$group, "HHT" = "HIT")

#recode hba1c values to decrease number of categories for table 1
data$hba1c <- data |> 
  mutate(hba1c = case_when(
    hba1c == "6.4% or lower" ~ "6.9% or lower",
    hba1c == "6.5% - 6.9%" ~ "6.9% or lower",
    hba1c == "7.0% - 7.4%" ~ "7.0% - 8.0%",
    hba1c == "7.5% - 7.9%" ~ "7.0% - 8.0%",
    hba1c == "8.0% - 8.4%" ~ "8.0% - 8.9%",
    hba1c == "8.5% - 8.9%" ~ "8.0% - 8.9%",
    hba1c == "9% or greater" ~ "9.0% or greater",
    hba1c == "I don't know my most recent HbA1c reading" ~ "Unkown by participant"
  )) |> 
  pull(hba1c)

data <- 
  set_label(data,
            age = "Age",
            income = "Income",
            gender = "Gender",
            cont_ladder = "Contemplation Ladder",
            edu = "Education",
            hba1c = "HbA1c")

```

Calculate Ordinal AUC, ANOVAs and posthoc tests for differences in AUC between groups

```{r}
#| label: ordinal_auc
#create wide dataframe with indiff points
wide_dd <- rbind(data %>%
                   filter(group == "EFT") %>%
                   select(id, group, mTurkCode, ac = eft_ac_correct,
                          eft_ip_30_1000:eft_ip_3650_1000) %>% 
                   rename("30" = eft_ip_30_1000, "90" = eft_ip_90_1000, "180" = eft_ip_180_1000,
                          "365" = eft_ip_365_1000, "1095" = eft_ip_1095_1000, "1825" = eft_ip_1825_1000,
                          "3650" = eft_ip_3650_1000), data %>% # start of HIT tibble
                   filter(group == "HIT") %>%
                   select(id, group, mTurkCode, ac = hit_ac, hit_ip_30_1000:hit_ip_3650_1000) %>% 
                   rename("30" = hit_ip_30_1000, "90" = hit_ip_90_1000, "180" = hit_ip_180_1000,
                          "365" = hit_ip_365_1000, "1095" = hit_ip_1095_1000, "1825" = hit_ip_1825_1000,
                          "3650" =hit_ip_3650_1000), data %>% # start of ncc tibble
                   filter(group == "NCC") %>%
                   select(id, group, mTurkCode, ac = ncc_ac, ncc_ip_30_1000:ncc_ip_3650_1000) %>% 
                   rename("30" = ncc_ip_30_1000, "90" = ncc_ip_90_1000, "180" = ncc_ip_180_1000,
                          "365" = ncc_ip_365_1000, "1095" = ncc_ip_1095_1000, "1825" = ncc_ip_1825_1000,
                          "3650" = ncc_ip_3650_1000)) %>% 
  mutate(ac = as.numeric(ac),
        group = fct_relevel(group, "EFT", "HIT", "NCC"))

#create long df of IPs
long_dd <- wide_dd %>% 
  pivot_longer(-id:-ac, names_to = "x", values_to = "y") %>% 
  mutate(x = as.numeric(x))

#we must name the three columns id, delay, and ip for this function to work
#create list of ids passing jb rules
#dropping rule 2 given the EFT intervention
passing_ids <- long_dd %>% 
  select(-group:-ac) %>% 
  mutate("x" = as.numeric(x)) %>% 
  rename("delay" = "x", "ip" = "y") %>% 
  jb_rules(.) %>% 
  filter(C1) %>% 
  dplyr::pull(id)

#create list of passing ids based on DD attention checks
passing_ids_ac <- wide_dd %>% 
  mutate("id" = as.character(id)) %>% 
  filter(ac >= .75) %>% 
  pull(id)

#Ordinal AUC calculations including all participants who finished

auc_ord_all <- long_dd %>% 
  prep_ordinal_all(., x_axis = "x") %>% 
  mutate(prop_y = y/1000) %>% 
  AUC(.,
      indiff = "prop_y",
      x_axis = "x_ord",
      max_x_axis = 7,
      amount = 1,
      groupings = c("id", "group"),
      type = "ordinal",
      prob_disc = FALSE,
  )

#Ordinal AUC calculations including only those who passed 3 of 4 DD attention checks
auc_ord_pass_ac <- auc_ord_all |> 
  filter(id %in% passing_ids_ac)

#quick look at mean/sd for both passing and failing
auc_ord_all %>% 
  group_by(group) %>% 
  summarize(mean_auc = mean(AUC), md_auc = median(AUC),
            sd_auc = sd(AUC), iqr_auc = IQR(AUC), n = n())

auc_ord_pass_ac %>% 
  group_by(group) %>% 
  summarize(mean_auc = mean(AUC), md_auc = median(AUC),
            sd_auc = sd(AUC), iqr_auc = IQR(AUC), n_auc = n())

# one way anova to test if values of ordinal AUC are the same in each group
#including only passing attention checks

pass_auc_model <- aov(AUC ~ group, auc_ord_pass_ac)
summary(pass_auc_model)
# check_model(pass_auc_model)
# report(pass_auc_model)

tukey_pass <- TukeyHSD((pass_auc_model))

#calculate effect sizes for Tukey HSD comparisons, passing ACs

#EFT vs. HIT cohen's D for mean difference
effectsize::cohens_d(
  x = auc_ord_pass_ac |> 
  filter(group == "EFT") |> 
  pull(AUC), 
  y = auc_ord_pass_ac |> 
    filter(group == "HIT") |> 
    pull(AUC))

#EFT vs. NCC cohen's D for mean difference
effectsize::cohens_d(
  x = auc_ord_pass_ac |> 
  filter(group == "EFT") |> 
  pull(AUC), 
  y = auc_ord_pass_ac |> 
    filter(group == "NCC") |> 
    pull(AUC))

#HIT vs. NCC cohen's D for mean difference
effectsize::cohens_d(
  x = auc_ord_pass_ac |> 
  filter(group == "NCC") |> 
  pull(AUC), 
  y = auc_ord_pass_ac |> 
    filter(group == "HIT") |> 
    pull(AUC))


# sensitivity analyses
# repeat ANOVA, posthoc, and posthoc effect size calculations for all finishers
all_auc_model <- aov(AUC ~ group, auc_ord_all)
summary(all_auc_model)
# check_model(all_auc_model)
# report(all_auc_model)

tukey_all <- TukeyHSD(all_auc_model, conf.level = .95)

#calculate effect sizes for Tukey HSD comparisons, including all finishers

#EFT vs. HIT cohen's D for mean difference
effectsize::cohens_d(
  x = auc_ord_all |> 
  filter(group == "EFT") |> 
  pull(AUC), 
  y = auc_ord_all |> 
    filter(group == "HIT") |> 
    pull(AUC))

#EFT vs. NCC cohen's D for mean difference
effectsize::cohens_d(
  x = auc_ord_all |> 
  filter(group == "EFT") |> 
  pull(AUC), 
  y = auc_ord_all |> 
    filter(group == "NCC") |> 
    pull(AUC))

#HIT vs. NCC cohen's D for mean difference
effectsize::cohens_d(
  x = auc_ord_all |> 
  filter(group == "NCC") |> 
  pull(AUC), 
  y = auc_ord_all |> 
    filter(group == "HIT") |> 
    pull(AUC))

#test for differences in DD AC scores between groups
#examine group means/medians/sds/var
#our variance in AC is less than the mean, suggesting low chance of
#over-dispersion in the model

wide_dd |> 
  group_by(group) |> 
  summarise(mean_ac = mean(ac),
            median_ac = median(ac),
            sd_ac = sd(ac),
            var_ac = var(ac),
            n_ac = n())

#examine distribution of AC scores by group
wide_dd |> 
  mutate(ac = as.factor(ac)) |>
  ggplot(aes(x = ac)) +
  geom_bar() +
  facet_wrap(~group)

#examine count data of AC scores by group
wide_dd |> 
  group_by(group, ac) |> 
  summarise(n_ac = n())

#kruskal-wallace to test for differences in distribution; fail to reject null
kruskal.test(ac ~ group, data = wide_dd)

#use logstic regression to test for differences in AC passing rates by groups
logit_model <- wide_dd |> 
  mutate(ac = case_when(
    ac >= .75 ~ 1,
    ac < .75 ~ 0,
  )) |> 
  glm(ac ~ group, family = "binomial", data = _)

summary(logit_model)
confint(logit_model)

#test statistic for comparison of model with predictors vs. null model: chi square
with(logit_model, null.deviance - deviance)

#degrees of freedom for the difference between full model and null model
with(logit_model, df.null - df.residual)

#p-value testing difference between model with predictors vs. model with just intercept (null model)
with(logit_model, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))

#no significant effect of group on log-odds of AC score passing

```

Examine distribution of EFT and HIT cue ratings during generation task

```{r}
#| label: cue_gen_ratings

#EFT and HIT cue gen ratings; pull data, join/shape
#EFT ratings
eft_ratings <- rawdata |> 
  filter(mTurkCode != 'NA' & Status == "IP Address" & group != 'NA' &
           StartDate > '2022-02-10 11:10:00') |> 
  mutate(mTurkCode = as.factor(mTurkCode), id = row_number(),
         id = as.factor(id), group = as.factor(group)) |> 
  select(id, group, Q3904_1:Q3904_4, Q3909_1:Q3909_4, Q3914_1:Q3914_4,
         Q3919_1:Q3919_4, Q3924_1:Q3924_4, Q3929_1:Q3929_4,
         Q3934_1:Q3934_4) 

# must now rename the 28 columns to reflect the characteristic being rated,
# and the cue being rated

# Create a vector of group suffixes
group_suffixes <- seq(1:7) %>% as.character()

# Define a function to generate the new column names
generate_eft_rating_names <- function(suffix) {
  c("liking", "important", "exciting", "vivid") %>%
    paste0("_", suffix) %>%
    set_names(c("liking", "important", "exciting", "vivid"))
}

# Map the function to generate new column names for each rating per cue
eft_rating_names <- map(group_suffixes, generate_eft_rating_names)

# Flatten the list of new column names into a single vector
eft_rating_names <- flatten_chr(eft_rating_names) |> as.vector()

# Rename the columns
eft_ratings <- eft_ratings %>%
  rename_with(~ eft_rating_names, -c(1:2))

#pivot longer, recode rating colum
eft_ratings <- eft_ratings |> 
  pivot_longer(-id:-group,
               names_to = c("characteristic", "cue_num"),
               names_sep = "_",
               values_to = "rating") |> 
  mutate(rating = 
           case_when(
             rating == "5 - Very Much" ~ 5,
             rating == 4 ~ 4,
             rating == 3 ~ 3,
             rating == 2 ~ 2,
             rating == "1 - Not at All" ~ 1
           )) |> 
  drop_na() 

## HIT ratings
hit_ratings <- rawdata |> 
  filter(mTurkCode != 'NA' & Status == "IP Address" & group != 'NA' &
           StartDate > '2022-02-10 11:10:00') |> 
  mutate(mTurkCode = as.factor(mTurkCode), id = row_number(),
         id = as.factor(id), group = as.factor(group)) |> 
  select(id, group, starts_with("hit_desc")) 

# must now rename the 28 columns to reflect the characteristic being rated,
# and the cue being rated

# Create a vector of group suffixes
group_suffixes <- seq(1:7) %>% as.character()

# Define a function to generate the new column names
generate_hit_rating_names <- function(suffix) {
  c("liking", "important", "exciting", "useful") %>%
    paste0("_", suffix) %>%
    set_names(c("liking", "important", "exciting", "useful"))
}

# Map the function to generate new column names for each rating per cue
hit_rating_names <- map(group_suffixes, generate_hit_rating_names)

# Flatten the list of new column names into a single vector
hit_rating_names <- flatten_chr(hit_rating_names) |> as.vector()

# Rename the columns
hit_ratings <- hit_ratings %>%
  rename_with(~ hit_rating_names, -c(1:2))

#pivot longer, recode rating colum
hit_ratings <- hit_ratings |> 
  mutate(across(.cols = 3:ncol(hit_ratings), .fns = as.character)) |> 
  pivot_longer(-id:-group,
               names_to = c("characteristic", "cue_num"),
               names_sep = "_",
               values_to = "rating") |> 
  mutate(rating = 
           case_when(
             rating == "5 - Very Much" ~ 5,
             rating == 4 ~ 4,
             rating == 3 ~ 3,
             rating == 2 ~ 2,
             rating == "1 - Not at All" ~ 1
           )) |> 
  drop_na() 

#bind eft and hit ratings together
cmbd_ratings <- bind_rows(eft_ratings, hit_ratings) 

#summary df of ratings by group and characteristic
rating_summary <- Rmisc::summarySE(
  data = cmbd_ratings, 
  measurevar = "rating",
  groupvar = c("group", "characteristic")
)

#create figure of of cue ratings by group and characteristic
rating_summary |> 
  mutate(group = 
           case_when(
             group == "EFT" ~ "EFT",
             group == "HHT" ~ "HIT"
           )) |> 
  rename(Rating = rating, Group = group, Characteristic = characteristic) |> 
  ggplot(aes(x = Characteristic, y = Rating, group = Group, color = Group,
             fill = Group)) +
  geom_col(position = "dodge") +
  geom_errorbar(aes(ymin = Rating - se, ymax = Rating + se),
                position = "dodge", color = "black") +
  ylim(0, 5) +
  beezdemand::theme_apa() +
  scale_fill_manual(values = c("EFT" = "#374E55FF",
                               "HIT" = "#DF8F44FF")) +
  scale_color_manual(values = c("EFT" = "#374E55FF",
                                "HIT" = "#DF8F44FF")) +
  labs(title = "Mean characteristic ratings for EFT and HIT Cues")

# ggsave("../remedi-hit-pilot/plots/supplemental-eft-hit-cue-ratings.png",
#        plot = last_plot(),
#        device = "png",
#        dpi = 1000,
#        height = 5,
#        width = 8)

#examine group and characteristic summary stats
cmbd_ratings |> 
  group_by(group, characteristic) |> 
  summarize(mean_rating = mean(rating),
            sd_rating = sd(rating),
            n_rating = n())

#fixed effects only comparisons
cmbd_ratings |> 
  filter(characteristic == "important") |> 
  group_by(id) |> 
  mutate(mean_rating = mean(rating)) |> 
  distinct(id, group, mean_rating) |> 
  t.test(mean_rating ~ group, data = _) 

#mixed effect model; random intercept for each participant
#problematic given the distribution of rating (not exactly continuous)
gmem <- cmbd_ratings |> 
  filter(characteristic == "liking") |> 
  lme4::lmer(rating ~ group + (1 | id), data = _)

summary(gmem)
performance::icc(gmem)

cmbd_ratings |> 
  group_by(id, characteristic) |> 
  summarize(mean_rating = mean(rating)) |> 
  pivot_wider(id_cols = id, 
              names_from = characteristic,
              values_from = mean_rating)
 
```

Demographics Table (Table 1)

```{r}
#| label: table_one

#create table one
# include all participants who finished regardless of dd attention checks

tableone <- data %>% 
  select(group, age, BMI, income, cont_ladder, hba1c, gender) %>% 
  tbl_summary(
    by = group,
    statistic = list(all_continuous() ~ "{median} ({p25}, {p75})",
                     all_categorical() ~ "{n} / {N} ({p}%)"),
    digits = all_continuous() ~ 2,
  ) %>% 
  add_overall() %>% 
  add_p(include = c("age", "BMI", "income", "cont_ladder", "gender", "hba1c")) |> 
  bold_labels() |>  
  modify_header(label = "**Variable**") %>% 
  modify_spanning_header(c("stat_1", "stat_2", "stat_3") ~ "**Group**")

#view table one
tableone

#save table
# tableone |>  
#   as_gt() |> 
#   gt::gtsave(filename = "plots/tableone.pdf")

```

Demographic Table for randomized completers vs. randomized noncompleters

```{r}
#| label: rand_completers_vs_noncompleters

#examine demographic differences between completers and non-completers 
#first, we must create a new df containing only participants who were randomized
#first, create three vectors of response ids that were randomized

eft_repids <- rawdata |> 
  filter(Status == "IP Address" & StartDate > '2022-02-10 11:10:00') |> 
  select(ResponseId, FL_12_DO_FL_32) |> 
  replace_na(replace = list(FL_12_DO_FL_32 = 0)) |> 
  filter(FL_12_DO_FL_32 == 1) |> 
  pull(ResponseId)

hit_repids <- rawdata |> 
  filter(Status == "IP Address" & StartDate > '2022-02-10 11:10:00') |> 
  select(ResponseId, FL_12_DO_FL_33) |> 
  replace_na(replace = list(FL_12_DO_FL_33 = 0)) |> 
  filter(FL_12_DO_FL_33 == 1) |> 
  pull(ResponseId)

ncc_repids <- rawdata |> 
  filter(Status == "IP Address" & StartDate > '2022-02-10 11:10:00') |> 
  select(ResponseId, FL_12_DO_FL_44) |> 
  replace_na(replace = list(FL_12_DO_FL_44 = 0)) |> 
  filter(FL_12_DO_FL_44 == 1) |> 
  pull(ResponseId)

#create df of participants who have been randomized, but may not have completed
ran_data <- rawdata |> 
  filter(ResponseId %in% eft_repids | ResponseId %in% hit_repids | ResponseId
         %in% ncc_repids) |> 
  mutate(completed = as_factor( 
    case_when(
      Progress == 100 ~ "Completed",
      Progress < 100 ~ "Voluntarily Withdrawn"
  )),
        group2 = case_when(
          FL_12_DO_FL_32 == 1 ~ "EFT",
          FL_12_DO_FL_33 == 1 ~ "HIT",
          FL_12_DO_FL_44 == 1 ~ "NCC"
        )) |> 
  rename(age = Q3988, edu = Q3982, gender = Q3987,
         income = Q3984, hba1c = Q206)

#recode income as an ordered factor

ran_data$income <- factor(ran_data$income, levels = c("$0 to $9,999",
                                              "$10,000 to $19,999",
                                              "$20,000 to $29,999",
                                              "$30,000 to $39,999",
                                              "$40,000 to $49,999",
                                              "$50,000 to $59,999",
                                              "$60,000 to $69,999",
                                              "$70,000 to $79,999",
                                              "$80,000 to $89,999",
                                              "$90,000 to $99,999",
                                              "$100,000 to $109,999",
                                              "$130,000 to $139,999",
                                              "$170,000 to $179,999",
                                              "$180,000 to $189,999"))

#recode income as a continuous variable in include in table 
ran_data$income <- ran_data |> 
  mutate(income = as.numeric(income),
         income = case_when(
           income == 1 ~ 4999.5,
           income == 2 ~ 1499.5,
           income == 3 ~ 24999.5,
           income == 4 ~ 34999.5, 
           income == 5 ~ 49999.5, 
           income == 6 ~ 54999.5,
           income == 7 ~ 64999.5,
           income == 8 ~ 74999.5,
           income == 9 ~ 84999.5,
           income == 10 ~ 94999.5,
           income == 11 ~ 104999.5,
           income == 12 ~ 134999.5,
           income == 13 ~ 174999.5, 
           income == 14 ~ 184999.5
         )) |> 
  pull(income)

ran_data$group <- recode_factor(ran_data$group, "HHT" = "HIT")

#recode hba1c values to decrease number of categories for table 
ran_data$hba1c <- ran_data |> 
  mutate(hba1c = case_when(
    hba1c == "6.4% or lower" ~ "6.9% or lower",
    hba1c == "6.5% - 6.9%" ~ "6.9% or lower",
    hba1c == "7.0% - 7.4%" ~ "7.0% - 8.0%",
    hba1c == "7.5% - 7.9%" ~ "7.0% - 8.0%",
    hba1c == "8.0% - 8.4%" ~ "8.0% - 8.9%",
    hba1c == "8.5% - 8.9%" ~ "8.0% - 8.9%",
    hba1c == "9% or greater" ~ "9.0% or greater",
    hba1c == "I don't know my most recent HbA1c reading" ~ "Unkown by participant"
  )) |> 
  pull(hba1c)


ran_data <- 
  set_label(ran_data,
            age = "Age",
            income = "Income",
            gender = "Gender",
            cont_ladder = "Contemplation Ladder",
            edu = "Education",
            hba1c = "HbA1c",
            completed = "Completion Status",
            group2 = "Group")

#create demographic table
completers_table <- ran_data |> 
  select(group2, age, BMI, income, completed,
         cont_ladder, hba1c, gender) %>% 
  tbl_summary(
    by = completed,
    statistic = list(all_continuous() ~ "{median} ({p25}, {p75})",
                     all_categorical() ~ "{n} / {N} ({p}%)"),
    digits = all_continuous() ~ 2,
  ) %>% 
  add_overall() %>% 
  add_p(include = c("age", "BMI", "income", "cont_ladder",
                    "gender", "hba1c", "group2")) |> 
  bold_labels() |>  
  modify_header(label = "**Variable**") %>% 
  modify_spanning_header(c("stat_1", "stat_2",) ~ "**Completion Status**")

#save table
# completers_table |>
#   as_gt() |>
#   gt::gtsave(filename = "../remedi-hit-pilot/plots/completers_table.pdf")

```

Discounting curve by group

```{r}
#| label: discounting_curve

# create df for plot: folks who passed AC, and their x/y values
plotdata <- wide_dd %>%
  select(-mTurkCode) %>% 
  pivot_longer(cols = `30`:`3650`, names_to = "x", values_to = "y") %>% 
  filter(id %in% passing_ids_ac) %>% 
  mutate(x = as.numeric(x))

#create plotdata for ordinal delays, passed AC
plotdata_ord <- long_dd %>% 
  filter(id %in% passing_ids_ac) %>% 
  prep_ordinal_all(., x_axis = "x")

#create df for mean, sd, and se of the plot, passed AC
plotdata_sum <- Rmisc::summarySE(data = plotdata, measurevar = "y", groupvars = c("group", "x")) %>% 
  rename(mn = y)

plotdataord_sum <- plotdata_sum %>% 
  as_tibble() %>% 
  prep_ordinal_all(., x_axis = "x") 
  
#create plot using ordinal x axis
pd_ord <- position_dodge(.1)

n_total <- data |> 
  nrow()

n_total_pass_ac <- data |> 
  filter(id %in% passing_ids_ac) |> 
  nrow()

indiffplot_ord <- plotdata_ord %>%
    ggplot(aes(x = x_ord, y = y,  color = group, group = group)) + 
    geom_point(aes(x = x_ord, y = mn, color = group), size = 2, data = plotdataord_sum, position = pd_ord) +
    geom_errorbar(aes(x = x_ord, y = mn, ymin = mn - se, ymax = mn + se, color = group),
                  data = plotdataord_sum, width = .15, size = .5, position = pd_ord) +
    # geom_line(aes(color = group, group = interaction(id, group)), alpha = .1, position = pd_ord) +
    geom_line(aes(x = x_ord, y = mn, color = group), data = plotdataord_sum, size = 1, position = pd_ord) +
    labs(title = "Average Indifference Points by Group",
         x = "Delay (ordinal)", y = "Indifference Point ($)",
                  subtitle = str_glue("N = {n_total_pass_ac}")) +
    beezdemand::theme_apa() +
    theme(legend.key.size = unit(1.5, "cm"),
          legend.background = element_rect(color = "black",
                                           fill = scales::alpha("white", .1),
                                           linetype = "solid"),
          legend.key = element_rect(fill ="white"),
          legend.position = c(.8, 1),
          legend.direction = "horizontal",
          legend.title = element_text(face = "bold")) +
    scale_x_continuous(breaks=c(1, 2, 3, 4, 5, 6, 7),
    labels = c("30 days", "90 days", "180 days", "365 days", "1095 days", "1825 days", "3650 days")) + # trans = 'log10')  +
    ggsci::scale_color_jama(name = "Group")

# ggsave("plots/group-ordinal-discounting-curves-fulldata.png", device = "png", dpi = 1000, width = 8, height = 5)

#create discounting curves for each group
#colors to match the main plot
colors <- bind_cols(pal_jama("default")(3), c("EFT", "HIT", "NCC")) |> 
  rename(color = ...1,
         group = ...2)

color_eft <- colors |> 
  filter(group == "EFT") |> 
  pull(color)

color_hit <- colors |> 
  filter(group == "HIT") |> 
  pull(color)

color_ncc <- colors |> 
  filter(group == "NCC") |> 
  pull(color)

#count group sizes, and sizes after passing DD attention checks
n_eft <- data |> 
  filter(group == "EFT") |> 
  nrow()

n_eft_pass_ac <- data |> 
  filter(group == "EFT" & id %in% passing_ids_ac) |> 
  nrow()

n_hit <- data |> 
  filter(group == "HIT") |> 
  nrow()

n_hit_pass_ac <- data |> 
  filter(group == "HIT" & id %in% passing_ids_ac) |> 
  nrow()

n_ncc <- data |> 
  filter(group == "NCC") |> 
  nrow()

n_ncc_pass_ac <- data |> 
  filter(group == "NCC" & id %in% passing_ids_ac) |> 
  nrow()

#EFT, passing AC
indiffplot_ord_eft <- plotdata_ord %>%
  filter(group == "EFT") %>%
    ggplot(aes(x = x_ord, y = y,  color = group, group = group)) + 
    geom_point(aes(x = x_ord, y = mn), data = plotdataord_sum %>%
                 filter(group == "EFT"), position = pd_ord, size = 2) +
    geom_errorbar(aes(x = x_ord, y = mn, ymin = mn - se, ymax = mn + se, color = group),
                  data = plotdataord_sum %>%
                    filter(group == "EFT"), width = .15, size = .5, position = pd_ord) +
    geom_line(aes(color = group, group = interaction(id, group)), alpha = .1, position = pd_ord) +
    geom_line(aes(x = x_ord, y = mn, color = group), data = plotdataord_sum %>%
                filter(group == "EFT"), size = 1, position = pd_ord) +
    labs(title = "Average Indifference Points - EFT",
         x = "Delay (ordinal)", y = "Indifference Point ($)",
         subtitle = str_glue("n = {n_eft_pass_ac}")) +
    beezdemand::theme_apa() +
    theme(legend.position = "none") +
    scale_x_continuous(breaks=c(1, 2, 3, 4, 5, 6, 7),
    labels = c("30", "90", "180", "365", "1095", "1825", "3650")) +
    scale_color_manual(values = c("EFT" = color_eft), name = "Group")

# HIT, passing AC
indiffplot_ord_hit <- plotdata_ord %>%
  filter(group == "HIT") %>%
    ggplot(aes(x = x_ord, y = y,  color = group, group = group)) + 
    geom_point(aes(x = x_ord, y = mn), data = plotdataord_sum %>%
                 filter(group == "HIT"), position = pd_ord, size = 2) +
    geom_errorbar(aes(x = x_ord, y = mn, ymin = mn - se, ymax = mn + se, color = group),
                  data = plotdataord_sum %>%
                    filter(group == "HIT"), width = .15, size = .5, position = pd_ord) +
    geom_line(aes(color = group, group = interaction(id, group)), alpha = .1, position = pd_ord) +
    geom_line(aes(x = x_ord, y = mn, color = group), data = plotdataord_sum %>%
                filter(group == "HIT"), size = 1, position = pd_ord) +
    labs(title = "Average Indifference Points - HIT",
         x = "Delay (ordinal)", y = "Indifference Point ($)",
                  subtitle = str_glue("n = {n_hit_pass_ac}")) +
    beezdemand::theme_apa() +
    theme(legend.position = "none") +
    scale_x_continuous(breaks=c(1, 2, 3, 4, 5, 6, 7),
    labels = c("30", "90", "180", "365", "1095", "1825", "3650")) +
    scale_color_manual(values = c("HIT" = color_hit), name = "Group")

# NCC, passing AC
indiffplot_ord_ncc <- plotdata_ord %>%
  filter(group == "NCC") %>%
    ggplot(aes(x = x_ord, y = y,  color = group, group = group)) + 
    geom_point(aes(x = x_ord, y = mn), data = plotdataord_sum %>%
                 filter(group == "NCC"), position = pd_ord, size = 2) +
    geom_errorbar(aes(x = x_ord, y = mn, ymin = mn - se, ymax = mn + se, color = group),
                  data = plotdataord_sum %>%
                    filter(group == "NCC"), width = .15, size = .5, position = pd_ord) +
    geom_line(aes(color = group, group = interaction(id, group)), alpha = .1, position = pd_ord) +
    geom_line(aes(x = x_ord, y = mn, color = group), data = plotdataord_sum %>%
                filter(group == "NCC"), size = 1, position = pd_ord) +
    labs(title = "Average Indifference Points - NCC",
         x = "Delay (ordinal)", y = "Indifference Point ($)",
                  subtitle = str_glue("n = {n_ncc_pass_ac}")) +
    beezdemand::theme_apa() +
    theme(legend.position = "none") +
    scale_x_continuous(breaks=c(1, 2, 3, 4, 5, 6, 7),
    labels = c("30", "90", "180", "365", "1095", "1825", "3650")) +
    scale_color_manual(values = c("NCC" = color_ncc), name = "Group")

#combine plots for a cool figure

ggarrange(
  indiffplot_ord,
  ggarrange(indiffplot_ord_eft, indiffplot_ord_hit, indiffplot_ord_ncc, 
            ncol = 3, labels = c("B", "C", "D")),
  nrow = 3, labels = "A"
)

# ggsave("../remedi-hit-pilot/plots/group-ordinal-discounting-curves-panel-plot.png", device = "png", dpi = 1000, width = 13, height = 15,
#        plot = last_plot())

### supplementary materials; recreate plots using all data
#create plotdata for ordinal delays, all finishers
plotdata_ord_all <- long_dd %>% 
  prep_ordinal_all(., x_axis = "x")

#recreate df for mean, sd, and se of the plot, all finishers
plotdata_sum_all <- Rmisc::summarySE(data = plotdata_ord_all, measurevar = "y", groupvars = c("group", "x")) %>% 
  rename(mn = y)

plotdataord_sum_all <- plotdata_sum_all %>% 
  as_tibble() %>% 
  prep_ordinal_all(., x_axis = "x") |> 
  mutate(group = fct_relevel(group, "EFT", "HIT", "NCC"))

#create discounting curve for all finishers
indiffplot_ord_all <- plotdata_ord_all %>%
    mutate(group = fct_relevel(group, "EFT", "HIT", "NCC")) |> 
    ggplot(aes(x = x_ord, y = y,  color = group, group = group)) + 
    geom_point(aes(x = x_ord, y = mn, color = group), size = 2, data = plotdataord_sum_all, position = pd_ord) +
    geom_errorbar(aes(x = x_ord, y = mn, ymin = mn - se, ymax = mn + se, color = group),
                  data = plotdataord_sum_all, width = .15, size = .5, position = pd_ord) +
    geom_line(aes(x = x_ord, y = mn, color = group), data = plotdataord_sum_all, size = 1, position = pd_ord) +
    labs(title = "Average Indifference Points by Group",
         x = "Delay (ordinal)", y = "Indifference Point ($)",
                  subtitle = str_glue("N = {n_total}")) +
    beezdemand::theme_apa() +
    theme(legend.key.size = unit(1.5, "cm"),
          legend.background = element_rect(color = "black",
                                           fill = scales::alpha("white", .1),
                                           linetype = "solid"),
          legend.key = element_rect(fill ="white"),
          legend.position = c(.8, 1),
          legend.direction = "horizontal",
          legend.title = element_text(face = "bold")) +
    scale_x_continuous(breaks=c(1, 2, 3, 4, 5, 6, 7),
    labels = c("30 days", "90 days", "180 days", "365 days", "1095 days", "1825 days", "3650 days")) + 
    ggsci::scale_color_jama(name = "Group") +
  guides(color = guide_legend(override.aes =
                                list(order = c("EFT", "HIT", "NCC"))))

#EFT, all finishers
indiffplot_ord_eft_all <- plotdata_ord_all %>%
  filter(group == "EFT") %>%
    ggplot(aes(x = x_ord, y = y,  color = group, group = group)) + 
    geom_point(aes(x = x_ord, y = mn), data = plotdataord_sum_all %>%
                 filter(group == "EFT"), position = pd_ord, size = 2) +
    geom_errorbar(aes(x = x_ord, y = mn, ymin = mn - se, ymax = mn + se, color = group),
                  data = plotdataord_sum_all %>%
                    filter(group == "EFT"), width = .15, size = .5, position = pd_ord) +
    geom_line(aes(color = group, group = interaction(id, group)), alpha = .1, position = pd_ord) +
    geom_line(aes(x = x_ord, y = mn, color = group), data = plotdataord_sum_all %>%
                filter(group == "EFT"), size = 1, position = pd_ord) +
    labs(title = "Average Indifference Points - EFT",
         x = "Delay (ordinal)", y = "Indifference Point ($)",
         subtitle = str_glue("n = {n_eft}")) +
    beezdemand::theme_apa() +
    theme(legend.position = "none") +
    scale_x_continuous(breaks=c(1, 2, 3, 4, 5, 6, 7),
    labels = c("30", "90", "180", "365", "1095", "1825", "3650")) +
    scale_color_manual(values = c("EFT" = color_eft), name = "Group")

# HIT, all finishers
indiffplot_ord_hit_all <- plotdata_ord_all %>%
  filter(group == "HIT") %>%
    ggplot(aes(x = x_ord, y = y,  color = group, group = group)) + 
    geom_point(aes(x = x_ord, y = mn), data = plotdataord_sum_all %>%
                 filter(group == "HIT"), position = pd_ord, size = 2) +
    geom_errorbar(aes(x = x_ord, y = mn, ymin = mn - se, ymax = mn + se, color = group),
                  data = plotdataord_sum_all %>%
                    filter(group == "HIT"), width = .15, size = .5, position = pd_ord) +
    geom_line(aes(color = group, group = interaction(id, group)), alpha = .1, position = pd_ord) +
    geom_line(aes(x = x_ord, y = mn, color = group), data = plotdataord_sum_all %>%
                filter(group == "HIT"), size = 1, position = pd_ord) +
    labs(title = "Average Indifference Points - HIT",
         x = "Delay (ordinal)", y = "Indifference Point ($)",
                  subtitle = str_glue("n = {n_hit}")) +
    beezdemand::theme_apa() +
    theme(legend.position = "none") +
    scale_x_continuous(breaks=c(1, 2, 3, 4, 5, 6, 7),
    labels = c("30", "90", "180", "365", "1095", "1825", "3650")) +
    scale_color_manual(values = c("HIT" = color_hit), name = "Group")

# NCC, all finishers
indiffplot_ord_ncc_all <- plotdata_ord_all %>%
  filter(group == "NCC") %>%
    ggplot(aes(x = x_ord, y = y,  color = group, group = group)) + 
    geom_point(aes(x = x_ord, y = mn), data = plotdataord_sum_all %>%
                 filter(group == "NCC"), position = pd_ord, size = 2) +
    geom_errorbar(aes(x = x_ord, y = mn, ymin = mn - se, ymax = mn + se, color = group),
                  data = plotdataord_sum_all %>%
                    filter(group == "NCC"), width = .15, size = .5, position = pd_ord) +
    geom_line(aes(color = group, group = interaction(id, group)), alpha = .1, position = pd_ord) +
    geom_line(aes(x = x_ord, y = mn, color = group), data = plotdataord_sum_all %>%
                filter(group == "NCC"), size = 1, position = pd_ord) +
    labs(title = "Average Indifference Points - NCC",
         x = "Delay (ordinal)", y = "Indifference Point ($)",
                  subtitle = str_glue("n = {n_ncc}")) +
    beezdemand::theme_apa() +
    theme(legend.position = "none") +
    scale_x_continuous(breaks=c(1, 2, 3, 4, 5, 6, 7),
    labels = c("30", "90", "180", "365", "1095", "1825", "3650")) +
    scale_color_manual(values = c("NCC" = color_ncc), name = "Group")

#combine plots for a cool figure

ggarrange(
  indiffplot_ord_all,
  ggarrange(indiffplot_ord_eft_all,
            indiffplot_ord_hit_all,
            indiffplot_ord_ncc_all, 
            ncol = 3, labels = c("B", "C", "D")),
  nrow = 3, labels = "A")

# ggsave("../remedi-hit-pilot/plots/supplement-group-ordinal-discounting-curves-all-panel-plot.png", device = "png", dpi = 1000, width = 13, height = 15,
#        plot = last_plot())

```

Boxplot of Ordinal AUC values

```{r}
#| label: auc_boxplot

sample <- auc_ord_pass_ac |> 
  group_by(group) |> 
  summarise(n = n())

auc_ord_pass_ac |> 
  left_join(sample) |> 
  mutate(x_axis = paste0(group, "\n", "n = ", n)) |> 
  ggplot(aes(x = x_axis, y = AUC)) + 
  geom_boxplot(aes(color = group), notch = TRUE) +
  geom_jitter(aes(color = group), alpha = .5, position = position_jitterdodge(jitter.width = 1)) +
  labs(x = "Group",
       y = "Ordinal AUC",
       title = "Ordinal AUC by group assignment") +
  theme_bw() +
      scale_color_manual(values = c("EFT" = color_eft, "HIT" = color_hit, "NCC" = color_ncc),
                         name = "Group")


# ggsave("../remedi-hit-pilot/plots/ordinal-auc-boxplot.png", device = "png", dpi = 1000, width = 10, height = 7, plot = last_plot())

### supplementary materials boxplot

sample_all <- auc_ord_all |> 
  group_by(group) |> 
  summarise(n = n())

auc_ord_all |> 
  left_join(sample_all) |> 
  mutate(x_axis = paste0(group, "\n", "n = ", n)) |> 
  ggplot(aes(x = x_axis, y = AUC)) + 
  geom_boxplot(aes(color = group), notch = TRUE) +
  geom_jitter(aes(color = group), alpha = .5, position = position_jitterdodge(jitter.width = 1)) +
  labs(x = "Group",
       y = "Ordinal AUC",
       title = "Ordinal AUC by group assignment") +
  theme_bw() +
      scale_color_manual(values = c("EFT" = color_eft, "HIT" = color_hit, "NCC" = color_ncc),
                         name = "Group")


# ggsave("../remedi-hit-pilot/plots/supplement-ordinal-auc-all-boxplot.png", device = "png", dpi = 1000, width = 10, height = 7, plot = last_plot())


```

Fisher's Exact test of randomized vs. finished participants

```{r}
#count number of participants randomized to EFT condition
#we must remove the pilots/previews before counting on the randomization variable
eft_all <- rawdata |> 
  filter(Status == "IP Address" & StartDate > '2022-02-10 11:10:00') |> 
  select(FL_12_DO_FL_32) |> 
  replace_na(replace = list(FL_12_DO_FL_32 = 0)) |> 
  sum()

#count number of participants randomized to EFT who finished experiment
eft_fin <- data |> 
  filter(group == "EFT") |> 
  nrow()

#count number of eft who voluntarily withdrew after randomization
eft_vw <- eft_all - eft_fin

#count number of participants randomized to HIT condition
hit_all <- rawdata |> 
  filter(Status == "IP Address" & StartDate > '2022-02-10 11:10:00') |> 
  select(FL_12_DO_FL_33) |> 
  replace_na(replace = list(FL_12_DO_FL_33 = 0)) |> 
  sum()

#count number of participants randomized to HIT who finished experiment
hit_fin <- data |> 
  filter(group == "HIT") |> 
  nrow()

#count number of hit who voluntarily withdrew after randomization
hit_vw <- hit_all - hit_fin

#count number of participants randomized to NCC condition
ncc_all <- rawdata |> 
  filter(Status == "IP Address" & StartDate > '2022-02-10 11:10:00') |> 
  select(FL_12_DO_FL_44) |> 
  replace_na(replace = list(FL_12_DO_FL_44 = 0)) |> 
  sum()

#count number of participants randomized to NCC who finished experiment
ncc_fin <- data |> 
  filter(group == "NCC") |> 
  nrow()

#count number of ncc who voluntarily withdrew after randomization
ncc_vw <- ncc_all - ncc_fin

n_randomized <- eft_all + hit_all + ncc_all

fisher_df <- tibble(eft = c(eft_vw, eft_fin),
                    hit = c(hit_vw, hit_fin),
                    ncc = c(ncc_vw, ncc_fin))

#fisher test for comparison withdrawal across all groups
fisher.test(fisher_df)

#pairwise fisher comparisons
rstatix::pairwise_fisher_test(fisher_df)
```

Flow diagram numbers

```{r}
#| label: consort_diagram_numbers

#Screened for eligibility. Date field to not include pilot participants,
# mturk_id field to not include testing, status to prevent survey previews.
n_screened <- rawdata |> 
  filter(Status == "IP Address" & StartDate > '2022-02-10 11:10:00') |> 
  nrow()

#excluded for any reason; total excluded
#simply subtract the included number from the total screened number
#the included number is the number of folks who were shown the consent waiver blocks
#we can't just use those who answered yes to this question, because some were shown but didn't
#get around to selecting yes and starting the study

n_excluded <- (rawdata |> 
  filter(Status == "IP Address" & StartDate > '2022-02-10 11:10:00') |> 
  nrow()) - (rawdata |>  
  filter(Status == "IP Address" & StartDate > '2022-02-10 11:10:00' &
           IP_country == "United States" & IP_block != 1) |> 
    filter(BMI >= 30 & diagnoses1_score == diagnoses2_score & !is.na(diagnoses1_5) & !is.na(diagnoses2_5) & is.na(diagnoses1_1) & is.na(diagnoses1_7) & is.na(diagnoses1_10) & is.na(diagnoses1_11) & is.na(diagnoses1_12) & is.na(diagnoses2_1) & is.na(diagnoses2_7) & is.na(diagnoses2_10) & is.na(diagnoses2_11) & is.na(diagnoses2_12) & diagnoses1_total <= 4 & diagnoses2_total <= 4) |> 
  nrow())


#attempted to screen, but was found using an IP address associated with a VPN/VPS 
n_ip_block_excluded <- rawdata |> 
  filter(Status == "IP Address" & StartDate > '2022-02-10 11:10:00') |> 
  filter(IP_block == 1) |> 
  nrow()

#create vectors of qualtrics response IDs to use for filtering in later calculations
ip_block_ids <- rawdata |> 
  filter(Status == "IP Address" & StartDate > '2022-02-10 11:10:00') |> 
  filter(IP_block == 1) |> 
  pull(ResponseId)

# attempted to screen, but ip from a country other than the US AND country is not empty (i.e., NA)
# filter out all responses that have already been excluded 
n_ip_country_excluded <- rawdata |> 
  filter(Status == "IP Address" & StartDate > '2022-02-10 11:10:00') |>
  filter(!ResponseId %in% ip_block_ids) |> 
  filter(IP_country != "United States" & !is.na(IP_country)) |> 
  nrow()

#create vector of response ids associated with bad countries
#must continue to filter our all responses that have already been excluded
ip_country_ids <- rawdata |> 
  filter(Status == "IP Address" & StartDate > '2022-02-10 11:10:00') |>
  filter(!ResponseId %in% ip_block_ids) |> 
  filter(IP_country != "United States" & !is.na(IP_country)) |> 
  pull(ResponseId)
         
         
### the following code to count the number of duplicate IP addresses will not run,
# because IP addresses have been removed from the public data set to protect participant privacy.
# The number of duplicate IP addresses screened out from the survey is 1736.

#number of duplicate IP addresses, preventing folks from continuing past the authentication block
#we must remove pilots/previews, and keep those who passed the IP address screens via IPHub
# n_duplicates <- rawdata |> 
#   filter(Status == "IP Address" & StartDate > '2022-02-10 11:10:00') |> 
#   filter(!ResponseId %in% ip_block_ids) |> 
#   filter(!ResponseId %in% ip_country_ids) |> 
#   select(Access) |>
#   duplicated() |> 
#   sum()

n_duplicates <- 1736

### the following code also cannot run, as 'Access' contained IP addresses,
# and has been removed from the deidentified raw data file. Instead, I have included a file
# in the data folder called "distinct_ips", which contains the qualtrics IDs of all
# non-duplicated IP addresses. 

#create vector of distinct IP addresses to keep in later calculations
# distinct_ips <- rawdata |> 
#   filter(Status == "IP Address" & StartDate > '2022-02-10 11:10:00') |> 
#   filter(!ResponseId %in% ip_block_ids) |> 
#   filter(!ResponseId %in% ip_country_ids) |>
#   select(ResponseId, Access) |> 
#   distinct(Access, .keep_all = TRUE) |> 
#   pull(ResponseId)

distinct_ips <- read_csv("data/distinct_ips.csv") |> 
  pull(distinct_ips)

# screened, excluding all previously dropped participants, but excluded for BMI, is not reporting type 2 diabetes in both questions,
# is not reporting the same diseases in both questions, is reporting colorectal cancer,
# is reporting breast cancer, is reporting copd, is reporting type 1 diabetes, is reporting
# none of the illnesses in this list

#diagnoses1_5 = t2dm, diagnoses1_1 = crc, diagnoses1_7 = breast cancer, diagnoses1_10 = copd,
#diagnoses1_11 = t1dm, diagnoses1_12 = none of the illnesses

#!is.na = they selected this. is.na = they did not select this. 

n_bmi_diag_excluded <- rawdata |> 
  filter(Status == "IP Address" & StartDate > '2022-02-10 11:10:00') |> 
  filter(!ResponseId %in% ip_block_ids) |> 
  filter(!ResponseId %in% ip_country_ids) |> 
  filter(ResponseId %in% distinct_ips) |> 
  select(BMI, diagnoses1_10:diagnoses1_12, diagnoses2_10:diagnoses2_12,
         diagnoses1_total, diagnoses2_total, diagnoses1_score, diagnoses2_score) |> 
  filter(BMI <= 29.9 | diagnoses1_score != diagnoses2_score | is.na(diagnoses1_5) | is.na(diagnoses2_5) | !is.na(diagnoses1_1) | !is.na(diagnoses1_7) | !is.na(diagnoses1_10) | !is.na(diagnoses1_11) | !is.na(diagnoses1_12) | !is.na(diagnoses2_1) | !is.na(diagnoses2_7) | !is.na(diagnoses2_10) | !is.na(diagnoses2_11) | !is.na(diagnoses2_12) | diagnoses1_total >= 5 | diagnoses2_total >= 5) |> 
  nrow()
  
#calculate total number of eligible participants
n_eligible <- n_screened - (n_ip_block_excluded + n_ip_country_excluded + n_duplicates + n_bmi_diag_excluded)

#count number of completed responses
n_completed <- data |> 
  nrow()

#those who were eligible but did not complete withdrew from the survey at some point
n_voluntary_withdrawal_pre_r <- n_eligible - n_randomized

#what percent of participants who screened were eligible to complete the study?
percent_eligible <- (n_eligible / n_screened) * 100



```

Create flow diagram

```{r}
#| label: flow_diagram_plot

#create plot foundation
consort <- tibble(x = 1:100, y = 1:100) |> 
  ggplot(aes(x, y)) +
  scale_x_continuous(minor_breaks = seq(10, 100, 10)) +
  scale_y_continuous(minor_breaks = seq(10, 100, 10)) +
  theme_linedraw()

#add n_screened box and text
consort <- consort +
  geom_rect(xmin = 34, xmax = 66, ymin = 94, ymax = 100, color='black',
            fill = 'white', linewidth = 0.25, linewidth = 0.25) +
  annotate('text', x = 50, y = 97, label = str_glue("Participants screened = {n_screened}"),
           size = 5)

#add n_eligible and n_excluded boxes
consort <- consort +
   geom_rect(xmin = 43, xmax=57, ymin=80, ymax=86, color='black',
            fill='white', linewidth = 0.25) +
  annotate('text', x= 50, y=83,label= str_glue("Eligible = {n_eligible}"), size = 5) +
  geom_rect(xmin = 71, xmax=95, ymin=78, ymax=99, color='black',
            fill='white', linewidth = 0.25) +
  annotate('text', x= 83, y=89,label= str_glue("Ineligible = {n_excluded} \n {n_ip_block_excluded} Using VPN \n {n_ip_country_excluded} Outside of US \n {n_duplicates} Duplicate screens \n {n_bmi_diag_excluded} BMI or diagnoses"), size = 5)

#add arrows between the top three boxes
consort <- consort +
  geom_segment(
    x=50, xend=50, y=94, yend=87, 
    size=0.15, linejoin = "mitre", lineend = "butt",
    arrow = arrow(length = unit(1, "mm"), type= "closed")) +
    geom_segment(
    x=50, xend=70.5, y=89, yend=89, 
    size=0.15, linejoin = "mitre", lineend = "butt",
    arrow = arrow(length = unit(1, "mm"), type= "closed"))

#add n_randomized and n_nol_withdrawal_prerandomization boxes
consort <- consort +
  geom_rect(xmin = 40, xmax=60, ymin=63, ymax=69, color='black',
            fill='white', linewidth = 0.25) +
  annotate('text', x= 50, y=66,label= str_glue("Randomized = {n_randomized}"), size = 5) +
  geom_rect(xmin = 66, xmax=100, ymin=69, ymax=75, color='black',
            fill='white', linewidth = 0.25) +
  annotate('text', x= 83.5, y=72,label= str_glue("{n_voluntary_withdrawal_pre_r} Vol. With. pre-randomization"), size = 5)

#add arrows to the randomized and vol with prerandomization boxes
consort <- consort +
  geom_segment(
    x=50, xend=50, y=80, yend=70, 
    size=0.15, linejoin = "mitre", lineend = "butt",
    arrow = arrow(length = unit(1, "mm"), type= "closed")) +
    geom_segment(
    x=50, xend=65.5, y=72, yend=72, 
    size=0.15, linejoin = "mitre", lineend = "butt",
    arrow = arrow(length = unit(1, "mm"), type= "closed"))

#add three arrows for each group, and horizontal line to connect arrows
consort <- consort +
  geom_segment(
  #middle arrow first
    x=50, xend=50, y=63, yend=55, 
    size=0.15, linejoin = "mitre", lineend = "butt",
    arrow = arrow(length = unit(1, "mm"), type= "closed")) +
  # then leftmost arrow, x and xend=10
  geom_segment(
    x=10, xend=10, y=60, yend=55, 
    size=0.15, linejoin = "mitre", lineend = "butt",
    arrow = arrow(length = unit(1, "mm"), type= "closed")) +
  # then rightmost arrow, x and xend=90
  geom_segment(
    x=90, xend=90, y=60, yend=55, 
    size=0.15, linejoin = "mitre", lineend = "butt",
    arrow = arrow(length = unit(1, "mm"), type= "closed")) +
  # then horizontal line, but remove the arrow
  geom_segment(
    x=10, xend=90, y=60, yend=60, 
    size=0.15, linejoin = "mitre", lineend = "butt")

#add the EFT, HIT, and NCC boxes

consort <- consort +
  #first box on left, EFT
  geom_rect(xmin = 1, xmax=19, ymin=48, ymax=54, 
              color='black', fill='white', size=0.25) +
  annotate('text', x= 10, y=51, size = 5,
             label= str_glue("{eft_all} EFT")) +
  
  #second box on left, HIT
  geom_rect(xmin = 41, xmax=59, ymin=48, ymax=54, 
              color='black', fill='white', size=0.25) +
  annotate('text', x= 50, y=51, size = 5,
             label=str_glue("{hit_all} HIT")) +
  
  #3rd box on left, NCC
  geom_rect(xmin = 81, xmax=99, ymin=48, ymax=54, 
              color='black', fill='white', size=0.25) +
  annotate('text', x= 90, y=51, size = 5,
             label= str_glue("{ncc_all} NCC"))

#add the three offset arrows below the randomization boxes
consort <- consort + 
  #first arrow on left
  geom_segment(
    x=2, xend=2, y=48, yend=30, 
    size=0.15, linejoin = "mitre", lineend = "butt",
    arrow = arrow(length = unit(1, "mm"), type= "closed")) +
  #2nd arrow on left
  geom_segment(
    x=42, xend=42, y=48, yend=30, 
    size=0.15, linejoin = "mitre", lineend = "butt",
    arrow = arrow(length = unit(1, "mm"), type= "closed")) +
#3rd arrow on left
  geom_segment(
    x=82, xend=82, y=48, yend=30, 
    size=0.15, linejoin = "mitre", lineend = "butt",
    arrow = arrow(length = unit(1, "mm"), type= "closed"))

#add the voluntary withdrawal after randomization boxes
consort <- consort +
  #first box from left, EFT
  geom_rect(xmin = 5, xmax=19, ymin=36, ymax=42, 
              color='black', fill='white', size=0.25) +
  annotate('text', x= 12, y=39, size = 5,
      label= str_glue("{eft_all - eft_fin} Vol. With.")) +
  
  #2nd box on left, HIT
  geom_rect(xmin = 45, xmax=59, ymin=36, ymax=42, 
              color='black', fill='white', size=0.25) +
  annotate('text', x= 52, y=39, size = 5,
      label= str_glue("{hit_all - hit_fin} Vol. With.")) +
  
  #3rd box from left, NCC
  geom_rect(xmin = 85, xmax=99, ymin=36, ymax=42, 
              color='black', fill='white', size=0.25) +
  annotate('text', x= 92, y=39, size = 5,
      label=  str_glue("{ncc_all - ncc_fin} Vol. With."))

#short arrows to connect voluntary withdrawal after randomization
consort <- consort +
  #first arrow on left
  geom_segment(
    x=2, xend=4.7, y=39, yend=39, 
    size=0.15, linejoin = "mitre", lineend = "butt",
    arrow = arrow(length = unit(1, "mm"), type= "closed")) +
  #2nd arrow on left
  geom_segment(
    x=42, xend=44.7, y=39, yend=39,  
    size=0.15, linejoin = "mitre", lineend = "butt",
    arrow = arrow(length = unit(1, "mm"), type= "closed")) +
#3rd arrow on left
  geom_segment(
    x=82, xend=84.7, y=39, yend=39, 
    size=0.15, linejoin = "mitre", lineend = "butt",
    arrow = arrow(length = unit(1, "mm"), type= "closed"))

#completed after randomization boxes
consort <- consort +
  #first box on left
  geom_rect(xmin = 1, xmax=19, ymin=24, ymax=30, 
              color='black', fill='white', size=0.25) +
  annotate('text', x= 10, y=27, size = 5,
             label= str_glue("{eft_fin} Completed")) +
  
  #2nd box on left
  geom_rect(xmin = 41, xmax=59, ymin=24, ymax=30, 
              color='black', fill='white', size=0.25) +
  annotate('text', x= 50, y=27, size = 5,
             label= str_glue("{hit_fin} Completed")) +
  
  #3rd box on left
  geom_rect(xmin = 81, xmax=99, ymin=24, ymax=30,  
              color='black', fill='white', size=0.25) +
  annotate('text', x= 90, y=27, size = 5,
             label= str_glue("{ncc_fin} Completed"))

#add  three more offset arrows below the completed boxes
consort <- consort + 
  #first arrow on left
  geom_segment(
    x=2, xend=2, y=24, yend=6, 
    size=0.15, linejoin = "mitre", lineend = "butt",
    arrow = arrow(length = unit(1, "mm"), type= "closed")) +
  #2nd arrow on left
  geom_segment(
    x=42, xend=42, y=24, yend=6, 
    size=0.15, linejoin = "mitre", lineend = "butt",
    arrow = arrow(length = unit(1, "mm"), type= "closed")) +
  #3rd arrow on left
  geom_segment(
    x=82, xend=82, y=24, yend=6, 
    size=0.15, linejoin = "mitre", lineend = "butt",
    arrow = arrow(length = unit(1, "mm"), type= "closed"))

#add the failed DD AC after completion boxes
consort <- consort +
  #first box from left, EFT
  geom_rect(xmin = 4, xmax=20, ymin=12, ymax=18, 
              color='black', fill='white', size=0.25) +
  annotate('text', x= 12, y=15, size = 5,
      label= str_glue("{eft_fin - n_eft_pass_ac} Failed DD AC")) +
  
  #2nd box on left, HIT
  geom_rect(xmin = 44, xmax=60, ymin=12, ymax=18, 
              color='black', fill='white', size=0.25) +
  annotate('text', x= 52, y=15, size = 5,
      label= str_glue("{hit_fin - n_hit_pass_ac} Failed DD AC")) +
  
  #3rd box from left, NCC
  geom_rect(xmin = 84, xmax=100, ymin=12, ymax=18, 
              color='black', fill='white', size=0.25) +
  annotate('text', x= 92, y=15, size = 5,
      label=  str_glue("{ncc_fin - n_ncc_pass_ac} Failed DD AC"))

# short arrows to connect failed DD AC after completed boxes
consort <- consort +
  #first arrow on left
  geom_segment(
    x=2, xend=3.7, y=15, yend=15, 
    size=0.15, linejoin = "mitre", lineend = "butt",
    arrow = arrow(length = unit(1, "mm"), type= "closed")) +
  #2nd arrow on left
  geom_segment(
    x=42, xend=43.7, y=15, yend=15,  
    size=0.15, linejoin = "mitre", lineend = "butt",
    arrow = arrow(length = unit(1, "mm"), type= "closed")) +
#3rd arrow on left
  geom_segment(
    x=82, xend=83.7, y=15, yend=15, 
    size=0.15, linejoin = "mitre", lineend = "butt",
    arrow = arrow(length = unit(1, "mm"), type= "closed"))

#passed DD AC and completed, analyzed boxes
consort <- consort +
  #first box on left
  geom_rect(xmin = 1, xmax=19, ymin=3, ymax=9, 
              color='black', fill='white', size=0.25) +
  annotate('text', x= 10, y=6, size = 5,
             label= str_glue("{n_eft_pass_ac} Analyzed")) + 
  
  #2nd box on left
  geom_rect(xmin = 41, xmax=59, ymin=3, ymax=9, 
              color='black', fill='white', size=0.25) +
  annotate('text', x= 50, y=6, size = 5,
             label= str_glue("{n_hit_pass_ac} Analyzed")) +
  
  #3rd box on left
  geom_rect(xmin = 81, xmax=99, ymin=3, ymax=9,  
              color='black', fill='white', size=0.25) +
  annotate('text', x= 90, y=6, size = 5,
             label= str_glue("{n_ncc_pass_ac} Analyzed"))

#remove background lines and axes
consort <- consort + 
  theme_void()

# ggsave("../remedi-hit-pilot/plots/flow_diagram.png", dpi = 1000, device = png, width = 10, height = 10)
# 
# ggsave("../remedi-hit-pilot/plots/flow_diagram.pdf", dpi = 1000, device = pdf, width = 10, height = 10)


```
